{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Assignment8_Solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fnysalehi/3D-Display-Simulation-using-Head-Tracking-with-Kinect/blob/master/Sheet8/Assignment8_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UnHoHsFop-8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, KFold, cross_val_predict\n",
        "from sklearn.calibration import calibration_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUswbzmRCHbj"
      },
      "source": [
        "def get_dataset_from_github(filename, index_col_str=None, header_str='infer'):    \n",
        "    data_file_path = \"https://raw.githubusercontent.com/FabriceBeaumont/4216_Biomedical_DS_and_AI/tree/main/Datasets\"\n",
        "    if index_col_str is None and header_str == 'infer':\n",
        "      data = pd.read_csv(data_file_path + filename)\n",
        "    elif index_col_str is None:\n",
        "        data = pd.read_csv(data_file_path + filename, header=header_str)\n",
        "    elif header_str == 'infer':\n",
        "      data = pd.read_csv(data_file_path + filename, index_col=index_col_str)\n",
        "    else:\n",
        "      data = pd.read_csv(data_file_path + filename, index_col=index_col_str, header=header_str)\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "Q3YXStZTEQGa",
        "outputId": "857a4489-46c2-427a-92f6-499c3627e535"
      },
      "source": [
        "titanic_survival_ds = get_dataset_from_github(\"/titanic_survival_data.csv\")\n",
        "# If this does not work, load the file (temporarily) into the Colab-File system (left side) \n",
        "# from your local files. Then execute as usual:\n",
        "# titanic_survival_ds = pd.read_csv(\"titanic_survival_data.csv\")\n",
        "\n",
        "titanic_survival_ds.head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0b362d9d2b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitanic_survival_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset_from_github\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/titanic_survival_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# If this does not work, load the file (temporarily) into the Colab-File system (left side)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# from your local files. Then execute as usual:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# titanic_survival_ds = pd.read_csv(\"titanic_survival_data.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-193c60db2222>\u001b[0m in \u001b[0;36mget_dataset_from_github\u001b[0;34m(filename, index_col_str, header_str)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/FabriceBeaumont/4216_Biomedical_DS_and_AI/tree/main/Datasets\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex_col_str\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mheader_str\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mindex_col_str\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m     )\n\u001b[1;32m    439\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# TODO: fsspec can also handle HTTP via requests, but leaving this unchanged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx0G72bGl7xc"
      },
      "source": [
        "## Biomedical Data Science & AI\n",
        "\n",
        "## Assignment 8\n",
        "\n",
        "#### Group members:  Fabrice Beaumont, Fatemeh Salehi, Genivika Mann, Helia Salimi, Jonah"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fhYMe5ml7xo"
      },
      "source": [
        "---\n",
        "### Exercise 1 - Ensemble Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_krKhWqo-Bv7"
      },
      "source": [
        "#### 1.1. Inform yourself about **gradient boosting**, then answer the following questions in your own words:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTjkofc690tY"
      },
      "source": [
        "In-depth resource for Gradient Boosting: https://explained.ai/gradient-boosting/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYHqa8s-92O3"
      },
      "source": [
        "Gradient Boosting is a machine learning technique which uses Gradient Descent and Boosting. It aims at fitting an additive model by introducing weak learners(i.e Decision trees) such that the recently added weak learner compensates the shortcomings of existing weak learners. The shortcoming of existing weak learners are identified by gradients in the loss function. Any user specified loss function  can be optimised by gradient boosting algorithm. The objective is to minimise the loss function by adding weak learners using Gradient Descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgUkN-nGziCe"
      },
      "source": [
        "a. What do the individual **weak learners** model? How does this relate to the\n",
        "gradient of the loss function?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKBxLpeY-Wf6"
      },
      "source": [
        "- The weak learners are trained with the objective of minimising the loss function, hence they are trained on the residuals of the model. Each new weak learner will be fitted on the **residual error** usually known as **pseudo-residual** produced by the existing sequence of learners.\n",
        "\n",
        "\n",
        "- The gradient boosting algorithm performs **gradient descent minimisation on some loss function** between true and predicted values. We perform gradient descent to bring the predicted values closer to true value by minimising the residual. The residual is a direction vector which not only provides the magnitude of difference between true and predicted value but also the direction of better approximation(minimization of loss function). Hence we are chasing the (negative)gradient of the loss function via gradient descent by chasing the direction of residual. Thus we perform gradient descent on the loss function.\n",
        "\n",
        "\n",
        "- The gradient boosted model that trains weak learners on residual vectors optimises mean squared error(MSE) - L2 Loss, while the model that trains weak learners on sign vector(only direction of residual without magnitude) optimises mean absolute error(MAE) - L1 loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh-CgF8k-JLD"
      },
      "source": [
        "b. What is the difference between **gradient boosting and random forest**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZivxSdGg-l9T"
      },
      "source": [
        "- Gradient Boosting is a forward stage-wise additive model, that builds and adds one tree at a time with the objective of minimising the loss function (computed by considering existing sequence of trees). Random forest builds all trees independently using random sample of data ( to prevent overfitting).\n",
        "\n",
        "\n",
        "- GB focuses step by step on difficult examples making it suitable for datasets with class imbalance. No such quality in present in RF. Additionally, any user specified loss function can be optimised by gradient boosting algorithm.\n",
        "\n",
        "\n",
        "- Random Forest combines the results of all the trees at the end after construction of all trees. Gradient Boosting on the other hand, takes the predictions of the sequence of trees into consideration at each stage of the algorithm.\n",
        "\n",
        "\n",
        "- If parameters are tuned carefully, gradient boosting can perform better than Random Forest. However it is difficult to tune GB as more parameters need to be tuned as compared to RF.\n",
        "\n",
        "\n",
        "- Gradient Boosting are more sensitive to overfitting if the data is noisy. Random Forest should be considered in this case.\n",
        "\n",
        "\n",
        "- Training GB generally takes longer then RF as trees are constructed sequentially."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appoDszfFI5l"
      },
      "source": [
        "#### 1.2. Which modifications make gradient boosting **robust against overfitting**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zAnH_KU-qip"
      },
      "source": [
        "Gredient Boosting is not robust against overfitting the training data as it is a greedy algorithm. This problem can be resolved by using regualarization methods which penalize different aspects of the algorithm. The following methods can be used:\n",
        "- **Tree constraints:** This is generally performed by following the heuristic that the more constrained the trees, the more the no. of trees need to construct the mode and vice-versa. The constraints can be imposed on the no. of trees (keep on adding trees until no improvement is observed), tree depth (shorter trees are preffered as deeper trees are considered more complex), no. of nodes/leaves of tree, no. of observations per split and minimum improvement to loss\n",
        "\n",
        "\n",
        "- **Weighted Updates:** The prediction of each tree is weighed by a learning rate or shrinkage to slow down the learning by the algorithm. Shrinkage reduces the influence of each individual tree and leaves space for future trees to improve the model.\n",
        "\n",
        "\n",
        "- **Stochastic Gradient Boosting:** The method aims at reducing the correlation between the sequence of trees of the algorithm. This is achieved by using only a subsample of the training data to fit base learner.\n",
        "\n",
        "\n",
        "- **Penalized Gradient Boosting:** Regression trees (a variant of decision trees which contain numeric values at leaf nodes) can be used in gradient boosting algorithm. The leaf values act as weights and can be regularised using L1 or L2 regularization to prevent overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyw9E17lFKxz"
      },
      "source": [
        "#### 1.3. Using the `titanic_survival_dataset.csv`, train the following models using nested cross validation while optimizing a selected number of hyperparameters in the inner loop using grid search, then compute the probabilities of your targets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdkdJx3c-ycE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "ae167842-8b71-46d9-e84f-7710c91ba575"
      },
      "source": [
        "# Load the dataset\n",
        "titanic_data = pd.read_csv('titanic_survival_data.csv')\n",
        "\n",
        "# Sepearate features and target\n",
        "y = titanic_data['Label'].ravel()\n",
        "X = titanic_data.drop(columns = ['Label'])\n",
        "\n",
        "titanic_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>no_cabin</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  Sex   Age  ...     Fare  Embarked  no_cabin  Label\n",
              "0            1       3    0  22.0  ...   7.2500         0         2      0\n",
              "1            2       1    1  38.0  ...  71.2833         1         1      1\n",
              "2            3       3    1  26.0  ...   7.9250         0         2      1\n",
              "3            4       1    1  35.0  ...  53.1000         0         1      1\n",
              "4            5       3    0  35.0  ...   8.0500         0         2      0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhfmrS-AFOra"
      },
      "source": [
        "#### 1.3.a) Random forest, optimizing the number of estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53pNibdz_vh7"
      },
      "source": [
        "# Random Forest classifier and parameter grid\n",
        "Random_Forest = RandomForestClassifier()\n",
        "p_grid_random_forest = {'n_estimators': [100, 150, 200, 300, 400]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2WoTW8B_xzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31292f97-4924-45b5-9b0d-ab5089ec1e9a"
      },
      "source": [
        "# Inner Fold - to obtain best hyperparameters\n",
        "Random_Forest_Fit = GridSearchCV(\n",
        "    estimator = Random_Forest,\n",
        "    param_grid = p_grid_random_forest,\n",
        "    cv = KFold(shuffle = True),\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "Random_Forest_Fit.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   10.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
              "             error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'n_estimators': [100, 150, 200, 300, 400]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81oe6w3d_6QW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fddb0bb8-17b4-4157-ca92-24c165c304af"
      },
      "source": [
        "# Outer Fold - to perform cross validation based on metrics and compute probabilities of target\n",
        "random_forest_prediction_prob = cross_val_predict(\n",
        "    estimator = Random_Forest_Fit,\n",
        "    X = X,\n",
        "    y = y,\n",
        "    cv = KFold(shuffle = True),\n",
        "    method = 'predict_proba', # to obtain prediction probabilities in result\n",
        "    verbose = 1\n",
        ")\n",
        "random_forest_prediction_prob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.5s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.5s finished\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   50.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8       , 0.2       ],\n",
              "       [0.09      , 0.91      ],\n",
              "       [0.38      , 0.62      ],\n",
              "       ...,\n",
              "       [0.83333333, 0.16666667],\n",
              "       [0.62      , 0.38      ],\n",
              "       [0.56      , 0.44      ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT5fcXYbFQKJ"
      },
      "source": [
        "#### 1.3.b) Gradient boosting, optimizing boosting steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqLsNOin_-zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a35abef-c42c-4546-9087-55ef2e2dbcf5"
      },
      "source": [
        "# Gradient Boosting classifier and parameter grid\n",
        "GB = GradientBoostingClassifier()\n",
        "p_grid_gb = {'n_estimators': [10, 50, 100, 200, 300]}\n",
        "\n",
        "# Inner Fold - to obtain best hyperparameters\n",
        "GB_Best_Clf = GridSearchCV(\n",
        "    estimator = GB,\n",
        "    param_grid = p_grid_gb,\n",
        "    cv = KFold(shuffle = True),\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "GB_Best_Clf.fit(X, y)\n",
        "\n",
        "# Outer Fold - to perform cross validation based on metrics and compute probabilities of target\n",
        "gb_prediction_prob = cross_val_predict(\n",
        "    estimator = GB_Best_Clf,\n",
        "    X = X,\n",
        "    y = y,\n",
        "    cv = KFold(shuffle = True),\n",
        "    method = 'predict_proba', # to obtain prediction probabilities in result\n",
        "    verbose = 1\n",
        ")\n",
        "gb_prediction_prob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    4.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.7s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.6s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.7s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.7s finished\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   19.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.79576565, 0.20423435],\n",
              "       [0.02813137, 0.97186863],\n",
              "       [0.54999021, 0.45000979],\n",
              "       ...,\n",
              "       [0.79742496, 0.20257504],\n",
              "       [0.37526572, 0.62473428],\n",
              "       [0.50738865, 0.49261135]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFoW86HYFRQr"
      },
      "source": [
        "#### 1.3.c) Lasso penalized logistic regression, optimizing $L_1$ regularization strength"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2VF4tZKAD_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46869d96-1584-49f9-eb22-7cda5b96cbc8"
      },
      "source": [
        "# Logistic Regression classifier and parameter grid\n",
        "LR = LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
        "p_grid_lr = {'C': [1000, 100, 10, 1, 0.1]}\n",
        "\n",
        "# Inner Fold - to obtain best hyperparameters\n",
        "LR_Best_Clf = GridSearchCV(\n",
        "    estimator = LR,\n",
        "    param_grid = p_grid_lr,\n",
        "    cv = KFold(shuffle = True),\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "LR_Best_Clf.fit(X, y)\n",
        "\n",
        "# Outer Fold - to perform cross validation based on metrics and compute probabilities of target\n",
        "lr_prediction_prob = cross_val_predict(\n",
        "    estimator = LR_Best_Clf,\n",
        "    X = X,\n",
        "    y = y,\n",
        "    cv = KFold(shuffle = True),\n",
        "    method = 'predict_proba', # to obtain prediction probabilities in result\n",
        "    verbose = 1\n",
        ")\n",
        "lr_prediction_prob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.88771981, 0.11228019],\n",
              "       [0.06686843, 0.93313157],\n",
              "       [0.41162293, 0.58837707],\n",
              "       ...,\n",
              "       [0.48296084, 0.51703916],\n",
              "       [0.36669758, 0.63330242],\n",
              "       [0.90396392, 0.09603608]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8u4nd5FAH8d"
      },
      "source": [
        "# Converting prediction probability results to dataframe\n",
        "lr_prob_result = pd.DataFrame(lr_prediction_prob, columns = ['0', '1'])\n",
        "gb_prob_result = pd.DataFrame(gb_prediction_prob, columns = ['0', '1'])\n",
        "rf_prob_result = pd.DataFrame(random_forest_prediction_prob, columns = ['0', '1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTrbd1slCDb7"
      },
      "source": [
        "(Using a large parameter grid results in an extended computation time. We advise using a maximum of *five* values per hyperparameter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NExXYSYPFL78"
      },
      "source": [
        "#### 1.4. Inform yourself about calibration curves (reliability diagrams). Use the predicted probabilities of each model from 3) to plot a calibration curve, then explain your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl0oasQ2AMD2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5add9bff-e3b9-46cd-c94b-22ad118ca938"
      },
      "source": [
        "# Compute fraction of positives and mean predicted value for plot\n",
        "fraction_of_positives_rf, mean_predicted_value_rf = calibration_curve(y, rf_prob_result['1'], n_bins = 10)\n",
        "fraction_of_positives_lr, mean_predicted_value_lr = calibration_curve(y, lr_prob_result['1'], n_bins = 10)\n",
        "fraction_of_positives_gb, mean_predicted_value_gb = calibration_curve(y, gb_prob_result['1'], n_bins = 10)\n",
        "\n",
        "plt.plot(mean_predicted_value_gb, fraction_of_positives_gb, marker = '.', label = 'Gradient Boosting')\n",
        "plt.plot(mean_predicted_value_rf, fraction_of_positives_rf, marker = '.', label = 'Random Forest')\n",
        "plt.plot(mean_predicted_value_lr, fraction_of_positives_lr, marker = '.', label = 'Logistic Regression')\n",
        "plt.plot([0,1], [0,1], linestyle = '--',label = 'Perfectly Calibrated')\n",
        "\n",
        "plt.xlabel('Mean Predicted Value')\n",
        "plt.ylabel('Fraction of positives')\n",
        "plt.title('Reliability Curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28Eku42XAUlZ"
      },
      "source": [
        "Calibration diagrams show how well calibrated the predicted probabilities of the model are with the true distribution of the class in data. The closer the plot is to the main diagonal, the better calibrated the probabilities of the model are. If the curves is below the main diagonal, the model has overforcast(the probabilities are too large). On the other hand if the curve is above the main diagonal,  the model has underforcast(the probabilities are too small).\n",
        "\n",
        "\n",
        "**Inference from Calibration Curves:** \n",
        "Gradient Boosting model and Logistic Regression are the most calibrated with plot that almost overlaps with the main diagonal(perfect calibration line) for some mean predicted values. Random Forest overforcasts and underforcasts the most between mean predicted value of 0.6 and 0.8. None of the models show very poor performance and this can be because we performed nested cross validation before reporting the results. All the plots are close to the perfect calibration line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v3MrpiqElLz"
      },
      "source": [
        "---\n",
        "### Exercise 2 - Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsbQAaMbY7q1"
      },
      "source": [
        "#### 2.1. Suppose there is a Multi-Layer Perceptron (MLP) composed of one input layer with *eight* neurons, followed by one hidden layer with *30* artificial neurons, and one output layer with *three* artificial neurons. All artificial neurons use the ReLU activation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjUHF7RUE3Cp"
      },
      "source": [
        "##### 2.1.a) Deduce the shape of input matrix $X$, hidden layer’s weight vector $W_h$, bias vector $b_h$ and the shape of the network’s output matrix $Y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP7qL3i0mGV4"
      },
      "source": [
        "If we suppose each $x_i$ has n features then: $X.shape = (n, 8)$ and $W_h.shape = (30,8)$ <br>\n",
        "So the shape of the term $XW_h^T$ will be $(n, 30)$ and it should be the same for $b_h^T \\Longrightarrow b_h.shape = (30, n)$<br>\n",
        "$H$ have the shape $(n, 30)$ and $W_o.shape = (3, 30)$ so the shape of the term $HW_o^T$ will be $(n, 3)$ and it should be the same for $b_o^T \\Longrightarrow b_o.shape = (3, n) \\Longrightarrow Y.shape = (n,3)$<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY1tnymZFBbW"
      },
      "source": [
        "##### 2.1.b) Write the equation that computes the network’s output matrix $Y$ as a function of $X$, $W_h$, $b_h$, $W_o$ and $b_o$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIxEwTAhbDit"
      },
      "source": [
        "activation function: $ReLU(X) =$ [ $max(0,x_i)$ for $x_i$ in $X$ ]<br>\n",
        "$H = ReLU(XW_h^T + b_h^T)$<br>\n",
        "$Y = ReLU(HW_o^T + b_o^T)$<br>\n",
        "$\\Longrightarrow Y = ReLU((ReLU(XW_h^T + b_h^T)) W_o^T + b_o^T)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6uiZwAlCnlr"
      },
      "source": [
        "#### 2.2. What are principle and unavoidable limitations of the backpropagation (BP)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UswnbGnvFDY5"
      },
      "source": [
        "#### 2.3. The shown figure is a *three* layer neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_o6m1LbBWyv"
      },
      "source": [
        "##### 2.3.a) Compute $h_1$, $h_2$, $o_1$, and the total error using ReLU units. \n",
        "\n",
        "*Note*: $b_1$, $b_2$ and $b_3$ represent the biases added to their respective units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEH0wipMxzc5"
      },
      "source": [
        "$h_1 = ReLU(i_1 \\times w_1 + i_2 \\times w_2 + b_1) = ReLU(0.5 \\times 0.15 + 0.8 \\times 0.2 + 0.4) = max(0.635, 0) = 0.635$\n",
        "\n",
        "$h_2 = ReLU(i_1 \\times w_3 + i_2 \\times w_4 + b_2) = ReLU(0.5 \\times 0.25 + 0.8 \\times 0.3 + 0.3) = max(0.665, 0) = 0.665$\n",
        "\n",
        "$o_1 = ReLU(h_1 \\times w_5 + h_2 \\times w_6 + b_3) = ReLU(0.635 \\times 0.4 + 0.665 \\times 0.55 + 0.6) = max(1.21975, 0) = 1.21975$\n",
        "\n",
        "$Error = \\frac{1}{2}(1 - 1.21975)^2 = 0.024145031249999976$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU705EzJBeP4"
      },
      "source": [
        "##### 2.3.b) Calculate the updates of the network weights $w_1, \\dots , w_6$ and bias terms $b_1$, $b_2$, $b_3$ using backpropagation. Assume a learning rate of $1$ for the\n",
        "sake of simplicity. \n",
        "\n",
        "*Note*: Remember that a bias term is equivalent to a weighted constant input 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBabTHc7_3Qp",
        "outputId": "52c0849d-1a1a-47b9-87dc-2e76eebe232b"
      },
      "source": [
        "!wget[](https://raw.githubusercontent.com/FabriceBeaumont/4216_Biomedical_DS_and_AI/main/Sheet8/sheet8_NN_sketch.png)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `https://raw.githubusercontent.com/FabriceBeaumont/4216_Biomedical_DS_and_AI/main/Sheet8/sheet8_NN_sketch.png'\n",
            "/bin/bash: -c: line 0: `wget[](https://raw.githubusercontent.com/FabriceBeaumont/4216_Biomedical_DS_and_AI/main/Sheet8/sheet8_NN_sketch.png)'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtFd0JZPDVK4"
      },
      "source": [
        "With:\n",
        "- $i_1 = 0.5$, $i_2 = 0.8$\n",
        "- $w_1 = 0.15$, $w_2 = 0.2$, $w_3 = 0.25$, $w_4 = 0.3$, $w_5 = 0.4$, $w_6 = 0.55$\n",
        "- $b_1 = 0.4$, $w_3 = 0.6$\n",
        "\n",
        "And the activation function for $h_1$ and $h_2$ is the ReLU. The expected outputis $1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aulNH2BmC5KU"
      },
      "source": [
        "---\n",
        "### Exercise 3- NN Programming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXYQj-xFD0-5"
      },
      "source": [
        "#### 3.1. Familiarize yourself with **tensorflow** and train a neural network with *two* hidden layers ($10$ and $8$ units respectively) and predict the label feature using the `titanic_survival_dataset.csv` dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmrdJKSXD5sR"
      },
      "source": [
        "#### 3.2. Evaluate the performance of the neural network for the same dataset in a nested cross validation by optimizing the number of units in the second hidden layer in the inner cross validation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqZp3FIBD7P_"
      },
      "source": [
        "#### 3.3. How does the neural network perform in comparison to the models in the calibration curve from the previous task and plot the results alongside the other models in the calibration plot?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yx8o12VEMOg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}